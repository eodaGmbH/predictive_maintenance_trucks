---
title: "Luftdrucksystemfehler bei Scania Trucks"
output: 
  flexdashboard::flex_dashboard:
    css: styles.css
    orientation: columns
    code_folding: hide
    vertical_layout: fill
---

```{r setup, eval = FALSE}
# execute this once after opening the project!

# library setup
library(flexdashboard)
library(magrittr)
library(dplyr)
library(caret)
library(purrr)
library(ggplot2)
library(stringr)
library(parallel)
library(doParallel)
library(knitr)
library(kableExtra)
library(rmarkdown)

# global options
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
options(scipen = 100)
```

```{r read_data, eval = FALSE}
# read csv data
data_trucks_training <- read.csv("aps_failure_training_set.csv", sep = ",", skip = 20, na.strings = "na")
data_trucks_test <- read.csv("aps_failure_test_set.csv", sep = ",", skip = 20, na.strings = "na")
```


Problematik
=======================================================================

Column {data-width=1}
-----------------------------------------------------------------------

### **Problemstellung** {data-height=700}
Der Scania-Trucks Datensatz kommt mit 171 anonymisierten Featuren sowie 76000 Observationen, welche im Verhältnis 60.000 zu 16.000 in Trainings- bzw. Testdaten aufgeteilt sind. Jede Observation enthält die Information, ob ein Fehler im Luftdruckssystem ( im Folgenden **LDS** genannt ) vorliegt oder nicht. <br><br>
Die Problemstellung lautet: <br>
<div class = "bordered">
*Sage für jede Observation im Testdatensatz voraus, ob ein Fehler im LDS vorliegt oder nicht. Minimiere dabei folgende Kostenfunktion:* <br>
**$cost(FP, FN) = 10 \cdot FP + 500 \cdot FN$** <br>
*Es handelt sich hierbei also um ein **Klassifizierungsproblem**, mit der Kostenfunktion $cost(FP, FN)$ als Metrik.* <br>
</div> <br>
**<u>Fehler 1. Art (FP):</u>** <br>
Der Fehler 1. Art, hier **F**alse **P**ositive, bedeutet, dass man einer Observation einen Fehler im LDS zuschreibt, obwohl das Fahrzeug fehlerfrei ist. Man schickt das Fahrzeug also in die Werkstatt, obwohl kein Fehler vorhanden ist. <br><br>
**<u>Fehler 2. Art (FN):</u>** <br>
Der Fehler 2. Art, hier **F**alse **N**egative, bedeutet, dass man eine Observation als fehlerfrei einstuft, obwohl das Fahrezeug einen Fehler im LDS aufweist. <br><br>
<div class = "bordered">
*Der Fehler 1. Art ist deutlich kostengünstiger gewichtet als der Fehler 2. Art. Es ist wesentlich günstiger einen LKW fälschlicherweise in die Werkstatt zur Überprüfung zu schicken, als dass ein LKW, bedingt durch einen **LDS-Fehler**, auf der Strecke liegen bleibt.*
</div> <br><br>

### **Hintergrund** {data-height=300}
Das Scania-Trucks Problem wurde auf der **IDA 2016** vorgestellt. Die IDA ist ein internationales Symposium über intelligente Datenanalyse, welche 2016 im Kontext des **maschinellen Lernens** das Industrieproblem für die Öffentlichkeit zugänglich gemacht hat. Scania, Mitsponsor der IDA, hat auf die beiden kostengünstigstens Modelle einen Preis von 500$ aussgeschrieben, sowie einen Rednerspot auf der **IDA** selbst. <br><br>

<div><img src = "Scania.png" alt = "Scania Logo" height = "100%" "width = "100%"></div>

Column {data-width=3}
----------------------------------------------------------------------

###
<center>
<div style = "display: inline-block; height: 90vh;"> <img src = "Titelbild.png" alt = "Titel" height = "100%"  width = "100%"></div>
</center>

Datensatz {data-orientation=rows}
===============================================

Row {data-height=200}
-----------------------------------------------

### **Klassenfeature**
Aus der Beschreibung des Scania-Trucks Problems lässt sich herauslesen, dass gewisse Feature Klassendaten abbilden. 
Das heißt, dass ein Feature auf mehrere Klasse aufgeteilt ist, wobei der Wert in der Klasse $A_i$ die Aufenthaltsdauer in der Klasse $A_i$ bedeutet, wobei $A$ das obergeordnete Feature ist. <br>
Beispielverteilung der Feature **ag** & **ay**:

<div style = "display: inline;">

<div style = "display: inline-block; width: 48%;"> 
```{r table_hist_ag}
# Example-table for the histogramm-feature
kable(data_trucks_training[1:5, str_detect(colnames(data_trucks_training), "ag_00+") == TRUE], "html", caption = "Klassendaten Feature ag") %>%
  kable_styling("striped")
```
</div>

<div style = "display: inline-block; width: 48%; margin-left: 15px;"> 
```{r table_hist_ay}
# Example-table for the histogramm-feature
kable(data_trucks_training[1:5, str_detect(colnames(data_trucks_training), "ay_00+") == TRUE], "html", caption = "Klassendaten Feature ay") %>%
  kable_styling("striped")
```
</div>

</div>

Row {data-height=300 .tabset .tabset-fade}
-----------------------------------------------

### Feature **ag**

```{r mean_hist_ag, eval = FALSE}
# calculate mean distribution for the ag feature
ag_labels <- paste0("ag_00", 0:9)
ag_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "ag_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
ag_mean_df <- data.frame(labels = ag_labels, mean = ag_mean)
```


<div style = "display: inline-block; width: 96vw;">

<div style = "float: left; width: 48%; margin-top: 20px;">
```{r plot_ag, out.width = "95%", fig.height = 3}
# plot ag distribution
ggplot(ag_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 48%; margin-top: 5vh; margin-left: 20px;">
```{r table_ag, out.width = "95%"}
ag_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "ag_000"):which(colnames(data_trucks) == "ag_009")]
for(i in 1:10) {
  ag_summary <- rbind(ag_summary, summary(sub_data_trucks[[i]]))
}
ag_summary <- cbind("Var" = paste0("ag_00", 0:9), ag_summary)
kable(ag_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>

### Feature **ay**

```{r mean_hist_ay, eval = FALSE}
# calculate mean distribution for the ay feature
ay_labels <- paste0("ay_00", 0:9)
ay_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "ay_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
ay_mean_df <- data.frame(labels = ay_labels, mean = ay_mean)
```


<div style = "display: inline-block; width: 96vw;">

<div style = "float: left; width: 48%; margin-top: 20px;">
```{r plot_ay, out.width = "95%", fig.height = 3}
# plot ay distribution
ggplot(ay_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 48%; margin-top: 5vh; margin-left: 20px;">
```{r table_ay, out.width = "95%"}
ay_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "ay_000"):which(colnames(data_trucks) == "ay_009")]
for(i in 1:10) {
  ay_summary <- rbind(ay_summary, summary(sub_data_trucks[[i]]))
}
ay_summary <- cbind("Var" = paste0("ay_00", 0:9), ay_summary)
kable(ay_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>

### Feature **az**

```{r mean_hist_az, eval = FALSE}
# calculate mean distribution for the az feature
az_labels <- paste0("az_00", 0:9)
az_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "az_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
az_mean_df <- data.frame(labels = az_labels, mean = az_mean)
```


<div style = "display: inline-block; width: 96vw;">

<div style = "float: left; width: 48%; margin-top: 20px;">
```{r plot_az, out.width = "95%", fig.height = 3}
# plot az distribution
ggplot(az_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 48%; margin-top: 5vh; margin-left: 20px;">
```{r table_az, out.width = "95%"}
az_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "az_000"):which(colnames(data_trucks) == "az_009")]
for(i in 1:10) {
  az_summary <- rbind(az_summary, summary(sub_data_trucks[[i]]))
}
az_summary <- cbind("Var" = paste0("az_00", 0:9), az_summary)
kable(az_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>

### Feature **ba**

```{r mean_hist_ba, eval = FALSE}
# calculate mean distribution for the ba feature
ba_labels <- paste0("ba_00", 0:9)
ba_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "ba_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
ba_mean_df <- data.frame(labels = ba_labels, mean = ba_mean)
```


<div style = "display: inline-block; width: 96vw;">

<div style = "float: left; width: 48%; margin-top: 20px;">
```{r plot_ba, out.width = "95%", fig.height = 3}
# plot ba distribution
ggplot(ba_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 48%; margin-top: 5vh; margin-left: 20px;">
```{r table_ba, out.width = "95%"}
ba_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "ba_000"):which(colnames(data_trucks) == "ba_009")]
for(i in 1:10) {
  ba_summary <- rbind(ba_summary, summary(sub_data_trucks[[i]]))
}
ba_summary <- cbind("Var" = paste0("ba_00", 0:9), ba_summary)
kable(ba_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>

### Feature **cn**

```{r mean_hist_cn, eval = FALSE}
# calculate mean distribution for the cn feature
cn_labels <- paste0("cn_00", 0:9)
cn_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "cn_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
cn_mean_df <- data.frame(labels = cn_labels, mean = cn_mean)
```


<div style = "display: inline-block; width: 96vw;">

<div style = "float: left; width: 48%; margin-top: 20px;">
```{r plot_cn, out.width = "95%", fig.height = 3}
# plot cn distribution
ggplot(cn_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 48%; margin-top: 5vh; margin-left: 20px;">
```{r table_cn, out.width = "95%"}
cn_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "cn_000"):which(colnames(data_trucks) == "cn_009")]
for(i in 1:10) {
  cn_summary <- rbind(cn_summary, summary(sub_data_trucks[[i]]))
}
cn_summary <- cbind("Var" = paste0("cn_00", 0:9), cn_summary)
kable(cn_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>

### Feature **cs**

```{r mean_hist_cs, eval = FALSE}
# calculate mean distribution for the cs feature
cs_labels <- paste0("cs_00", 0:9)
cs_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "cs_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
cs_mean_df <- data.frame(labels = cs_labels, mean = cs_mean)
```


<div style = "display: inline-block; width: 96vw;">

<div style = "float: left; width: 48%; margin-top: 20px;">
```{r plot_cs, out.width = "95%", fig.height = 3}
# plot cs distribution
ggplot(cs_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 48%; margin-top: 5vh; margin-left: 20px;">
```{r table_cs, out.width = "95%"}
cs_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "cs_000"):which(colnames(data_trucks) == "cs_009")]
for(i in 1:10) {
  cs_summary <- rbind(cs_summary, summary(sub_data_trucks[[i]]))
}
cs_summary <- cbind("Var" = paste0("cs_00", 0:9), cs_summary)
kable(cs_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>

### Feature **ee**

```{r mean_hist_ee, eval = FALSE}
# calculate mean distribution for the ee feature
ee_labels <- paste0("ee_00", 0:9)
ee_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "ee_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
ee_mean_df <- data.frame(labels = ee_labels, mean = ee_mean)
```



<div style = "display: inline-block; width: 96vw;">

<div style = "float: left; width: 48%; margin-top: 20px;">
```{r plot_ee, out.width = "95%", fig.height = 3}
# plot ee distribution
ggplot(ee_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 48%; margin-top: 5vh; margin-left: 20px;">
```{r table_ee, out.width = "95%"}
ee_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "ee_000"):which(colnames(data_trucks) == "ee_009")]
for(i in 1:10) {
  ee_summary <- rbind(ee_summary, summary(sub_data_trucks[[i]]))
}
ee_summary <- cbind("Var" = paste0("ee_00", 0:9), ee_summary)
kable(ee_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>

Feature-Engineering
=========================================

Column {data-width=100}
-----------------------------------------

### **NA-Analyse**

Der Scania-Trucks Datensatz weist eine hohe Zahl an fehlenden Werten ( hier im Folgenden **NA's** genannt) auf. <br>
Eine Möglichkeit besteht darin, eine gewisse Anzahl an NA's zuzulassen und dementsprechend die Anzahl der Feature zu reduzieren. Alle Observationen, welche nach der **Featurereduktion** noch NA's enthalten, werden entfernt. Unterschieden wird zwischen allen Observationen ( fehlerfrei & fehlerhaft ), und den fehlerhaften Observationen ( Observationen die einen Fehler aufweisen ). <br>
Die Anzahl der vorhandenen NA's in jedem der 171 Feature liefert uns die verschiedenen **NA-Grenzen**. <br>
Folgende Auszug aus der Tabelle liefert einen Überblick über die NA Grenzen: 

```{r NA_data_frame, eval = FALSE}
# setup the whole dataset
data_trucks <- rbind(data_trucks_training, data_trucks_test)

# generate data frame for the na boundaries
na_df <- data.frame(Var = colnames(data_trucks), 
                    Na = sapply(data_trucks, function(x) sum(is.na(x))))

# get unique na breakpoints for all features
na_breaks <- na_df$Na %>% unique() %>% sort()

result_NA <- data_frame(na_number = na_breaks, vars = numeric(length = length(na_breaks)),
                        obs = numeric(length = length(na_breaks)),
                        obs_pos = numeric(length(na_breaks)))
# calculate the feature_gain / observation_loss for all na boundaries
for (i in na_breaks){
  
  select_columns <- 
    which(na_df$Na <= i) %>% 
    as.numeric()
  
  sub_trucks <- data_trucks[ , select_columns] %>% na.omit()
  
  n_obs <- nrow(sub_trucks)
  n_vars <- ncol(sub_trucks)
  n_obs_pos <- sub_trucks[sub_trucks$class == "pos", ] %>% count() %>% as.numeric()
  
  result_NA$vars[result_NA$na_number == i] = n_vars
  result_NA$obs[result_NA$na_number == i] = n_obs
  result_NA$obs_pos[result_NA$na_number == i] = n_obs_pos
}

# get the relative gain / loss
result_NA <- result_NA %>%
  mutate(vars_percent = (vars / ncol(data_trucks)) * 100, 
         obs_percent = (obs / nrow(data_trucks)) * 100,
         obs_pos_percent = (obs_pos / nrow(data_trucks[data_trucks$class == "pos", ])) * 100)
```

<br>

```{r NA_table}
# print table for the na boundaries
kable(result_NA %>% head(5), "html", caption = "NA Grenzen, Featureanzahl ( Grün ), allgemeiner Observationsverlust ( Orange ) & fehlerhafter Observationsverlust ( Blau )") %>%
  kable_styling("striped") %>%
  column_spec(c(2,5), background = "#88ab33", color = "white") %>%
  column_spec(c(3,6), background = "#F98948", color = "white") %>%
  column_spec(c(4,7), background = "#437F97", color = "white") 
```

<br>

<center>
```{r NA_plot}
# plot the na boundaries respective to the gain / loss
ggplot(result_NA) + 
  geom_point(aes(na_number, vars_percent), color = "#88ab33") +
  geom_point(aes(na_number, obs_percent), color = "#F98948") +
  geom_point(aes(na_number, obs_pos_percent), color = "#437F97") +
  xlab("NA Anzahl") + ylab("") +
  scale_y_continuous(limits = c(1, 100)) 
```
</center>

<br>

<div class = "bordered">
<center>**Featuregewinnung:**</center> <br>
Aus der Tabelle lässt sich erkennen, dass bei den unterschiedlichen NA-Grenzen die Anzahl an **gewonnener Feature** stark schwankt. So gewinnt man beim Sprung von 0 auf 195 NA's lediglich 1 Feature dazu, beim Sprung von 861 auf 863 NA's aber direkt 30 Feature. Das **NA-Verhalten** ist also alles andere als proportional. <br>
Die Entscheidung, welche NA-Grenze man als Auschlussverfahren nimmt, hängt aber nicht nur von der Featuregewinnung ab.
</div> <br>
<div class = "bordered">
<center>**Allgemeiner Observationsverlust:**</center> <br>
Alle Feature im späteren Modell zu berücksichten würde nichts bringen, wenn man nur noch auf 5% der ursprünglichen Daten trainieren kann. Deshalb spielt der **Observationsverlust** eine starke Rolle in der Entscheidung. Hier zeichnet sich ein starker Sprung von 5598 auf 12012 NA's ab. Evaluiert man also die Grenzen anhand des Observationsverlustes, sollte man nicht über die Grenze von 5598 hinaus gehen, da direkt danach c.a. 10% der LKW's zusätzlich verloren gehen. 
</div> <br>
Der Scania-Trucks Datensatz weist noch ein Problem zusätzlich auf. Von den 76000 Observationen sind lediglich **1375** fehlerhaft. Dadurch könnte es passieren, dass wir bei der Wahl der NA-Grenze alle fehlerhaften Observationen verlieren. <br>
Demnach muss zusätzlich folgende Variable mit einkalkuliert werden: <br><br>
<div class = "bordered">
<center>**Fehlerhafter Observationsverlust:**</center> <br>
Der fehlerhafte Oberservationsverlust beschreibt die Anzahl der Observationen die bei der Wahl der NA-Grenze verloren gehen und zusätzlich einen Fehler im LDS aufweisen. Anhand der geringen Fehlerrate im Datensatz wäre es fatal, zu viele der fehlerhaften Fahrzeuge zu verlieren, da ein Modell so möglicherweise auf ausschließlich fehlerfreien Daten trainieren könnte. Die Grenze für fehlerhafte Observationen findet sich in der Tabelle offensichtlich beim Sprung von 928 NA's auf 3188 NA's. Obwohl man hier nur 1 Feature dazu gewinnen würde, fallen 30% der fehlerhaften Observationen dadurch raus. Die Grenze ist demnach also bei 928 NA's zu setzen.
</div> <br>
<center>**<u>Fazit:</u>**</center>
Die NA-Analyse zeigt, dass verschiedene Breakpoints existieren, um eine gewisse Anzahl von Featuren zu erhalten / nicht zu viele Observationen zu verlieren. Als ein erster Gedankengang ist diese Art der Analyse nicht schlecht und verschafft einen guten Überblick über den Datensatz, der individuelle Informationsgehalt der einzelnen Feature wird dabei aber nicht berücksichtigt. Um außerdem auf dem kompletten Trainingsset vorhersagen treffen zu können, müssen die fehlenden Werte aufgefüllt werden, anstatt **NA-Reduktion** zu betreiben. Hierzu stehen Möglichkeiten wie beispielsweise die **knn-imputation** zur Verfügung. Im Pre-Processing-Tab wird diese Möglichkeit evaluiert.




Column {data-width=100}
-----------------------------------------

### **Datenaufbereitung ( Relativierung )**


Die **Datensatzanalyse** hat gezeigt, dass viele der Klassendaten nicht gleichmäßig verteilt sind.
Oftmals sind die Klassen eines Klassenfeatures für fast alle Observationen 0, andere Klassen hingegen sind mit den unterschiedlichsten Größenordnungen von Zahlen gefüllt. <br>
Hinzu kommt, dass die Werte in den verschiedenen Klassen **absolute** Daten sind: <br><br>
<center>
<div class = "bordered" style = "width: 30vw; font-size: 20px;">
**$\sum_{i = 0}^{9}{A_i}$** <br><br>
ist **nicht notwendigerweise gleich** für alle Observationen.
</div> 
</center>

<br>

Um das Problem der absoluten Klassendaten zu beseitigen ist es sinnvoll diese zu **relativieren**. Man stellt also jeden absoluten Wert in $A_i$ in **prozentuellen Bezug** zu der **Gesamtaufenthaltszeit** der Observation in der Klasse $A$. <br>
Dadurch ergibt sich folgende Formel für die neuen Werte $\tilde{A}$: <br><br>
<center>
<div class = "bordered" style = "font-size: 20px; width: 30vw;">
**$\tilde{A}_i = \frac{A_i}{\sum_{i = 0}^{9}{A_i}}  mit  \sum_{i = 0}^{9}{\tilde{A}_i} = 1$** <br><br>
für **jede** Observation.
</div>
</center>
<br>

**<u>Vorher:</u>** <br>

```{r hist_ag_before_table}
# example table of the histogramm feature  ag before qualifying the data
kable(data_trucks_training[1:5, str_detect(colnames(data_trucks_training), "ag_00+") == TRUE], "html", caption = "Klassenfeature ag") %>%
  kable_styling("striped")
```

```{r histogramm_percentage, eval = FALSE}
# qualify the histogramm data
data_trucks_perc <- data_trucks %>%
  mutate(
    perc_ag_0 = ag_000 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_1 = ag_001 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_2 = ag_002 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_3 = ag_003 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_4 = ag_004 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_5 = ag_005 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_6 = ag_006 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_7 = ag_007 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_8 = ag_008 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_9 = ag_009 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ay_0 = ay_000 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_1 = ay_001 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_2 = ay_002 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_3 = ay_003 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_4 = ay_004 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_5 = ay_005 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_6 = ay_006 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_7 = ay_007 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_8 = ay_008 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_9 = ay_009 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_az_0 = az_000 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_1 = az_001 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_2 = az_002 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_3 = az_003 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_4 = az_004 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_5 = az_005 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_6 = az_006 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_7 = az_007 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_8 = az_008 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_9 = az_009 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_ba_0 = ba_000 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_1 = ba_001 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_2 = ba_002 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_3 = ba_003 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_4 = ba_004 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_5 = ba_005 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_6 = ba_006 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_7 = ba_007 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_8 = ba_008 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_9 = ba_009 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_cn_0 = cn_000 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_1 = cn_001 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_2 = cn_002 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_3 = cn_003 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_4 = cn_004 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_5 = cn_005 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_6 = cn_006 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_7 = cn_007 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_8 = cn_008 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_9 = cn_009 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cs_0 = cs_000 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_1 = cs_001 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_2 = cs_002 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_3 = cs_003 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_4 = cs_004 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_5 = cs_005 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_6 = cs_006 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_7 = cs_007 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_8 = cs_008 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_9 = cs_009 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_ee_0 = ee_000 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_1 = ee_001 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_2 = ee_002 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_3 = ee_003 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_4 = ee_004 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_5 = ee_005 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_6 = ee_006 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_7 = ee_007 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_8 = ee_008 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_9 = ee_009 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009)
  )

data_trucks_perc <- data_trucks_perc[, !str_detect(names(data_trucks_perc), "ag_00+|ay_00+|az_00+|ba_00+|cn_00+|cs_00+|ee_00+")]
```

<br>

**<u>Nachher:</u>** <br>

```{r hist_ag_after_table}
# example table of the histogramm feature ag after qualifying the data
kable(data_trucks_perc[1:5, str_detect(colnames(data_trucks_perc), "perc_ag_+") == TRUE], "html", caption = "Klassenfeature ag relativiert") %>%
  kable_styling("striped", position = "left" )
```

Column {data-width=100}
-----------------------------------------

### **Pre-Processing**

```{r Pre-Process, eval = FALSE}
# setup the knn imputation
data_trucks_knn <- preProcess(data_trucks_perc, method = "knnImpute")

data_trucks_knn_training <- predict(data_trucks_knn, data_trucks_perc[1:60000, ])
data_trucks_knn_test <- predict(data_trucks_knn, data_trucks_perc[60001:76000, ])
```

Zusätzlich zu seinen Klassendaten verfügt der Datensatz über, wie bereits erwähnt, eine vielzahl von **NA's** ( fehlende Werte ). <br>
Eine Möglichkeit, diese aufzufüllen, bietet hier die **knn-Imputation** ( *k-nearest-neighbours-Schätzung* ). <br><br>
Die Schätzung erfolgt in **3** Schritten. <br>
<center>
<font size = "13px"><font color = "#88ab33">Zentrieren</font>, <font color = "#F98948">Skalieren</font> & <font color = "#437F97">Schätzen</font></font>
</center>

<br>

Folgende Tabellenausschnitte verdeutlicht diese Schritte: <br><br>

<div style = "display: inline;">

<div style = "display: inline-block; width: 49%;">
```{r standard_table}
# example table before preProcessing 
kable(data_trucks[["ad_000"]] %>% head(5), "html") %>%
  kable_styling("striped") 
```
</div>

<div style = "display: inline-block; width: 49%;">
```{r center_table}
# example table after centering
kable((data_trucks[["ad_000"]] - mean(data_trucks[["ad_000"]], na.rm = TRUE)) %>% head(5), "html") %>%
  kable_styling("striped") %>%
  column_spec(1, background = "#88ab33", color = "white")
```
</div>

</div>

<div style = "display: inline;">

<div style = "display: inline-block; width: 49%;">
```{r scale_table}
# example table after centering and scaling
kable(((data_trucks[["ad_000"]] - mean(data_trucks[["ad_000"]], na.rm = TRUE)) / sd(data_trucks[["ad_000"]], na.rm = TRUE)) %>% head(5), "html") %>%
  kable_styling("striped") %>% 
  column_spec(1, background = "#F98948", color = "white")
```
</div>

<div style = "display: inline-block; width: 49%">
```{r impute_table}
# example table after centering, scaling and knn imputation
kable(data_trucks_knn_training[["ad_000"]] %>% head(5), "html") %>%
  kable_styling("striped") %>%
  column_spec(1, background = "#437F97", color = "white")
```
</div>

</div>



Modellierung
===============================

```{r evaluation_functions, eval = FALSE}
# helperfunctions for cost evaluation and sensitivity / specificity calculation for given thresholds
sensspec_rate <- function(threshold, predicted_set, test_set) {
  predicted_class <- ifelse(predicted_set$neg > threshold, "neg", "pos")
  return(confusionMatrix(predicted_class, test_set$class)$table %>% data.frame() %>% extract2("Freq"))
}

min_cost_func <- function(threshold_vec, predicted_set, test_set) {
  false_negatives <- sapply(threshold_vec, function(x) sensspec_rate(x, predicted_set, test_set)[3])
  false_positives <- sapply(threshold_vec, function(x) sensspec_rate(x, predicted_set, test_set)[2])

  threshold_df <- data.frame(threshold = threshold_vec,
                             false_positives = false_positives,
                             false_negatives = false_negatives)
  
  threshold_df <- threshold_df %>%
    mutate(
      cost = false_positives * 10 + false_negatives * 500
    )
  
  return(threshold_df)
}
```


Column {data-width=100}
------------------------------

### **Modellauswahl & Güte**

Zur Lösung des **Klassifizierungsproblems** wird ein **Random-Forest-Modell** verwendet. Als **Parameterraster** wird $mtry = 13$ und $splitrule =$ *gini-Index* verwendet. <br>
Der Standardwert von $mtry = \sqrt{Anzahl \space der\space Feature}$ hat sich gegenüber verschiedenen Werten durchgesetzt. Der *gini-Index* wurde jeweils vom Modell als beste *splitrule* gewählt.

<br><br>

<center>**<u>Modell 1:</u> 10-fache, 5-faltige Kreuzvalidierung mit 500 Bäumen**</center> <br>

```{r rf_model_cv10_0.5k, eval = FALSE}
# model 2 - random forest with 10 times 5 folded cross validation and 500 trees
control_knn_cv_five_ten <- trainControl(method = "repeatedcv",
                                        number = 5,
                                        repeats = 10,
                                        allowParallel = TRUE,
                                        classProbs = TRUE,
                                        verboseIter = TRUE,
                                        summaryFunction = mnLogLoss)

grid_knn <- expand.grid(mtry = 13, splitrule = "gini", min.node.size = 1)

cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)

system.time(
  model_knn_cv10_0.5k <- train(class ~ .,
                               data = data_trucks_knn_training,
                               method = "ranger",
                               metric = "logLoss",
                               importance = "impurity",
                               verbose = TRUE,
                               trControl = control_knn_cv_five_ten,
                               tuneGrid = grid_knn,
                               num.trees = 500)
)

stopCluster(cluster)
registerDoSEQ()

```

```{r evaluation_cv10_0.5k, eval = FALSE}
# get optimal classificationthreshold to minimize the cost function for model 2
pred_cv10_0.5k <- predict(model_knn_cv10_0.5k, data_trucks_knn_test, type = "prob")

threshold_df_cv10_0.5k <- min_cost_func(seq(from = 0.93, to = 0.95, length.out = 100), pred_cv10_0.5k, data_trucks_knn_test)
min_cost_place_cv10_0.5k <- which(threshold_df_cv10_0.5k$cost == min(threshold_df_cv10_0.5k$cost))[1]
min_threshold_cv10_0.5k <- threshold_df_cv10_0.5k$threshold[min_cost_place_cv10_0.5k]
min_cost_cv10_0.5k <- threshold_df_cv10_0.5k$cost[min_cost_place_cv10_0.5k]
pred_cv10_0.5k_class <- ifelse(pred_cv10_0.5k$neg >= min_threshold_cv10_0.5k, "neg", "pos")
```

<div style = "display: inline;">

<div style = "display: inline-block; vertical-align: text-top;">
```{r confusion_cv10_0.5k_display}
# display the confusion Matrix of model 2
confusionMatrix(pred_cv10_0.5k_class, data_trucks_knn_test$class)
```
</div>

<div style = "display: inline-block; vertical-align: text-top;">
```{r model_cv10_0.5k_display}
# display model 2
model_knn_cv10_0.5k
```
<br>
<center>
<u>***Ergebnis:***</u> <br><br>
***Kosten:** `r min_cost_cv10_0.5k`* <br><br>
***Kosten pro LKW:** `r min_cost_cv10_0.5k / nrow(data_trucks_knn_test)`*
</center>
</div>

</div>

<br><br>

<center>**<u>Modell 2:</u> 10-fache, 5-faltige Kreuzvalidierung mit 1000 Bäumen**</center> <br>

```{r rf_model_cv10_1k, eval = FALSE}
# model 3 - random forest with 10 times 5 folded cross validation with 1000 trees
control_knn_cv_five_ten <- trainControl(method = "repeatedcv",
                                        number = 5,
                                        repeats = 10,
                                        allowParallel = TRUE,
                                        classProbs = TRUE,
                                        verboseIter = TRUE,
                                        summaryFunction = mnLogLoss)

grid_knn <- expand.grid(mtry = 13, splitrule = "gini", min.node.size = 1)

cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)

system.time(
  model_knn_cv10_1k <- train(class ~ .,
                             data = data_trucks_knn_training,
                             method = "ranger",
                             metric = "logLoss",
                             importance = "impurity",
                             verbose = TRUE,
                             trControl = control_knn_cv_five_ten,
                             tuneGrid = grid_knn,
                             num.trees = 1000)
)

stopCluster(cluster)
registerDoSEQ()

```

```{r evaluation_cv10_1k, eval = FALSE}
# get optimal classificationthreshold to minimize the cost function for model 3
pred_cv10_1k <- predict(model_knn_cv10_1k, data_trucks_knn_test, type = "prob")

threshold_df_cv10_1k <- min_cost_func(seq(from = 0.97, to = 0.98, length.out = 100), pred_cv10_1k, data_trucks_knn_test)
min_cost_place_cv10_1k <- which(threshold_df_cv10_1k$cost == min(threshold_df_cv10_1k$cost))[1]
min_threshold_cv10_1k <- threshold_df_cv10_1k$threshold[min_cost_place_cv10_1k]
min_cost_cv10_1k <- threshold_df_cv10_1k$cost[min_cost_place_cv10_1k]
pred_cv10_1k_class <- ifelse(pred_cv10_1k$neg >= min_threshold_cv10_1k, "neg", "pos")
```

<div style = "display: inline;">

<div style = "display: inline-block; vertical-align: text-top;">
```{r confusion_cv10_1k_display}
# display confusion Matrix of model 3
confusionMatrix(pred_cv10_1k_class, data_trucks_knn_test$class)
```
</div>

<div style = "display: inline-block; vertical-align: text-top;">
```{r model_cv10_1k_display}
# display model 3
model_knn_cv10_1k
```
<center>
<br>
<u>***Ergebnis:***</u> <br><br>
***Kosten:** `r min_cost_cv10_1k`* <br><br>
***Kosten pro LKW:** `r min_cost_cv10_1k / nrow(data_trucks_knn_test)`*
</center>
</div>

</div>

<br><br>

<center>**<u>Modell 3:</u> 10-fache, 5-faltige Kreuzvalidierung mit 2500 Bäumen**</center> <br>

```{r rf_model_cv10_2.5k, eval = FALSE}
# model 4- random forest with 10 times 5 folded cross validation with 2500 trees
control_knn_cv_five_ten <- trainControl(method = "repeatedcv",
                                        number = 5,
                                        repeats = 10,
                                        allowParallel = TRUE,
                                        classProbs = TRUE,
                                        verboseIter = TRUE,
                                        summaryFunction = mnLogLoss)

grid_knn <- expand.grid(mtry = 13, splitrule = "gini", min.node.size = 1)

cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)

system.time(
  model_knn_cv10_2.5k <- train(class ~ .,
                               data = data_trucks_knn_training,
                               method = "ranger",
                               metric = "logLoss",
                               importance = "impurity",
                               verbose = TRUE,
                               trControl = control_knn_cv_five_ten,
                               tuneGrid = grid_knn,
                               num.trees = 2500)
)

stopCluster(cluster)
registerDoSEQ()

```

```{r evaluation_cv10_2.5k, eval = FALSE}
# get optimal classification threshold to minimize the cost function for model 4
pred_cv10_2.5k <- predict(model_knn_cv10_2.5k, data_trucks_knn_test, type = "prob")

threshold_df_cv10_2.5k <- min_cost_func(seq(from = 0.95, to = 0.96, length.out = 100), pred_cv10_2.5k, data_trucks_knn_test)
min_cost_place_cv10_2.5k <- which(threshold_df_cv10_2.5k$cost == min(threshold_df_cv10_2.5k$cost))[1]
min_threshold_cv10_2.5k <- threshold_df_cv10_2.5k$threshold[min_cost_place_cv10_2.5k]
min_cost_cv10_2.5k <- threshold_df_cv10_2.5k$cost[min_cost_place_cv10_2.5k]
ggplot(threshold_df_cv10_2.5k, aes(x = threshold_df_cv10_2.5k$threshold, y = threshold_df_cv10_2.5k$cost)) +
  geom_line()
```

<div style = "display: inline;">

<div style = "display: inline-block; vertical-align: text-top;">
```{r confusion_cv10_2.5k_display}
# display confusion Matrix of model 4
confusionMatrix(pred_cv10_2.5k_class, data_trucks_knn_test$class)
```
</div>

<div style = "display: inline-block; vertical-align: text-top;">
```{r model_cv10_2.5k_display}
# display model 4
model_knn_cv10_1k
```
<center>
<br>
<u>***Ergebnis:***</u> <br><br>
***Kosten:** `r min_cost_cv10_2.5k`* <br><br>
***Kosten pro LKW:** `r min_cost_cv10_2.5k / nrow(data_trucks_knn_test)`*
</center>
</div>

</div>

Column {data-width=100}
------------------------------

### **Variablenwichtigkeit**

<center>**<u>Modell 1:</u>**</center> <br>

```{r variable-_importance_cv10_0.5k, eval = FALSE}
# get variable importance of model 2
var_imp_df_cv10_0.5k <- data.frame(Variable = rownames(varImp(model_knn_cv10_0.5k)[[1]]), Importance = varImp(model_knn_cv10_0.5k)[[1]]$Overall,
                                  Rank = rank(varImp(model_knn_cv10_0.5k)[[1]]$Overall)) %>%
  arrange(desc(Rank))
```

```{r var_imp_cv10_0.5k_table}
# display variable importance of model 2
kable(var_imp_df_cv10_0.5k[, 1:2] %>% head(5), "html") %>%
  kable_styling("striped")
```

<br><br>

<center>**<u>Modell 2:</u>**</center> <br>

```{r variable_importance_cv10_1k, eval = FALSE}
# get variable importance of model 3
var_imp_df_cv10_1k <- data.frame(Variable = rownames(varImp(model_knn_cv10_1k)[[1]]), Importance = varImp(model_knn_cv10_1k)[[1]]$Overall,
                                  Rank = rank(varImp(model_knn_cv10_1k)[[1]]$Overall)) %>%
  arrange(desc(Rank))
```

```{r var_imp_cv10_1k_table}
# display variable importance of model 3
kable(var_imp_df_cv10_1k[, 1:2] %>% head(5), "html") %>%
  kable_styling("striped")
```

<br><br>

<center>**<u>Modell 3:</u>**</center> <br>

```{r variable_importance_cv10_2.5k, eval = FALSE}
# get variable importance of model 4
var_imp_df_cv10_2.5k <- data.frame(Variable = rownames(varImp(model_knn_cv10_2.5k)[[1]]), Importance = varImp(model_knn_cv10_2.5k)[[1]]$Overall,
                                  Rank = rank(varImp(model_knn_cv10_2.5k)[[1]]$Overall)) %>%
  arrange(desc(Rank))
```

```{r var_imp_cv10_2.5k_table}
# display variable importance of model 4
kable(var_imp_df_cv10_2.5k[, 1:2] %>% head(5), "html") %>%
  kable_styling("striped")
```

### **Laufzeit**

<center>**<u>Specs:</u>**</center>

<center>
*Intel(R) Core(TM) i5-6200U CPU @ 2.30GHz, 2400 MHz, 2 Kerne, 4 logische Prozessoren, 8GB RAM* <br>
*Gerechnet wurde auf 3 Prozessoren*
</center>

<br>

<center>**<u>Modell 1:</u>**</center> <br>

<center>**$Laufzeit \approx 1 \space Stunde \space 11 \space Minuten$**</center>

<br>

<center>**<u>Modell 2:</u>**</center> <br>

<center>**$Laufzeit \approx 2 \space Stunden \space 21 \space Minuten$**</center>

<br>

<center>**<u>Modell 3:</u>**</center> <br>

<center>**$Laufzeit \approx 5 \space Stunden \space 57 \space Minuten$**</center>

Vorhersagefaktoren
=======================================================

Um die verursachten Kosten der Modelle ( Modellierungs-Tab ) ausrechnen zu können, muss nach der Vorhersage der Wahrscheinlichkeiten noch klassifiziert werden. Hierfür muss ein threshold gewählt werden, nachdem eine Observation entweder der fehlerhaften oder der fehlerfreien Klasse zugeordnet werden. <br>
Dies geschieht in 3 Schritten: <br>
1.) Berechne die Kosten für die thresholds im Intervall $[0,1]$ mit Schrittweite $\frac{1}{100}$ <br>
Wiederhole: <br>
2.) Plotte die Kostenfunktion und ermittle einen Bereich, in dem das Minimum vorliegt <br>
3.) Wähle das Intervall $[a,b]$ in dem das Minimum vorliegt, um dieses genauer zu bestimmen


Column
-------------------------------------------------------

### **Modell 1 ( 10-fache, 5-faltige Kreuzvalidierung mit 500 Bäumen )**

```{r cv10_0.5k_plot}
ggplot(threshold_df_cv10_0.5k, aes(x = threshold_df_cv10_0.5k$threshold, y = threshold_df_cv10_0.5k$cost)) +
  geom_line() +
  theme_minimal() +
  xlab("threshold") + ylab("Kosten") +
  ggtitle("", subtitle = "Finaler Plot im Intervall [0.93, 0.95]")
```

<center>

<u>**Optimaler threshold:**</u> <br>
*`r min_threshold_cv10_0.5k`*

</center>

<br>

<i>Ist der Algorithmus sich zu $\approx$ `r (min_threshold_cv10_0.5k*100) %>% signif(digits = 4)`% sicher, dass eine Observation fehlerfrei ist, klassifiziere diese als fehlerfrei, andernfalls klassifiziere sie als fehlerhaft. </i>

Column
--------------------------------------------------------

### **Modell 2 ( 10-fache, 5-faltige Kreuzvalidierung mit 1000 Bäumen )**

```{r cv10_1k_plot}
ggplot(threshold_df_cv10_1k, aes(x = threshold_df_cv10_1k$threshold, y = threshold_df_cv10_1k$cost)) +
  geom_line() +
  theme_minimal() +
  xlab("threshold") + ylab("Kosten") +
  ggtitle("", subtitle = "Finaler Plot im Intervall [0.97, 0.98]")
```

<center>

<u>**Optimaler threshold:**</u> <br>
*`r min_threshold_cv10_1k`*

</center>

<br>

<i>Ist der Algorithmus sich zu $\approx$ `r (min_threshold_cv10_1k*100) %>% signif(digits = 4)`% sicher, dass eine Observation fehlerfrei ist, klassifiziere diese als fehlerfrei, andernfalls klassifiziere sie als fehlerhaft. </i>

Column
--------------------------------------------------------

### **Modell 3 ( 10-fache, 5-faltige Kreuzvalidierung mit 2500 Bäumen )**

```{r cv10_2.5k_plot}
ggplot(threshold_df_cv10_2.5k, aes(x = threshold_df_cv10_2.5k$threshold, y = threshold_df_cv10_2.5k$cost)) +
  geom_line() +
  theme_minimal() +
  xlab("threshold") + ylab("Kosten") +
  ggtitle("", subtitle = "Finaler Plot im Intervall [0.95, 0.96]")
```

<center>

<u>**Optimaler threshold:**</u> <br>
*`r min_threshold_cv10_2.5k`*

</center>

<br>

<i>Ist der Algorithmus sich zu $\approx$ `r (min_threshold_cv10_2.5k*100) %>% signif(digits = 4)`% sicher, dass eine Observation fehlerfrei ist, klassifiziere diese als fehlerfrei, andernfalls klassifiziere sie als fehlerhaft. </i>

Kostenvergleich {data-orientation=rows}
=======================================================
Um die Kostenersparnis unseres "Siegermodells" festzustellen benötigen wir Vergleichswerte. Nehmen wir im Folgenden an, es existieren keine datenanalytischen Methoden um dem Luftdruckssystemfehler in gewisser Weise vorzubeugen. Wie würde man vorgehen?

Row  {data-height=300}
------------------------------------------------------

### **Guessing at Random**
Eine Möglichkeit bietet sich darin, einfach zu raten. Sicherlich nicht besonders effektiv, aber vielleicht lassen sich so ein paar der betroffenen LKW's vorsorglich in die Werkstatt schicken. <br><br>

<center>
```{r guessing_at_random}
random_class <- character(length = length(data_trucks_test))
rand_num <- runif(16000)
random_class <- ifelse(rand_num < 0.5, "pos", "neg")

random_conf <- confusionMatrix(random_class, data_trucks_test$class)
random_conf

random_table <- random_conf$table %>% as.data.frame() %>% extract2("Freq") 
random_cost <- random_table[2] * 10 + random_table[3] * 500
```

<br>

<u><i>**Kosten: **</i></u>`r random_cost` <br>
<u><i>**Kosten pro LKW: **</i></u>`r random_cost/nrow(data_trucks_test)` <br>

</center>

### **Das wird schon**
Eine weiter Möglichkeit wäre, auf sein Glück zu vertrauen und keinen LKW in die Werkstatt zu schicken, "das wird schon". Auch wenn das sehr riskant ist, sind, wie bereits in der Datensatzanalyse gezeigt, nur wenige der LKW's überhaupt betroffen. <br><br>

<center>
```{r complete_luck}
luck_class <- rep("neg", 16000)

luck_conf <- confusionMatrix(luck_class, data_trucks_test$class)
luck_conf

luck_table <- luck_conf$table %>% as.data.frame() %>% extract2("Freq")
luck_cost <- luck_table[2] * 10 + luck_table[3] * 500
```

<br>

<u><i>**Kosten: **</i></u>`r luck_cost` <br> 
<u><i>**Kosten pro LKW: **</i></u>`r luck_cost/nrow(data_trucks_test)`<br> 

</center>

### **Sicher ist sicher**
Eine letzte Möglichkeit liefert die "Sicherheitsvariante". Wenn man jeden LKW in die Werkstatt schickt, kann zumindest kein Fehler übersehen werden, aber auch das bringt natürlich gewisse Kosten mit sich. <br><br>

<center>
```{r safe}
safe_class <- rep("pos", 16000)

safe_conf <- confusionMatrix(safe_class, data_trucks_test$class)
safe_conf
safe_table <- safe_conf$table %>% as.data.frame() %>% extract2("Freq")
safe_cost <- safe_table[2] * 10 + safe_table[3] * 500
```

<br>

<u><i>**Kosten: **</i></u>`r safe_cost` <br> 
<u><i>**Kosten pro LKW: **</i></u>`r safe_cost/nrow(data_trucks_test)`<br> 

</center>

Row {data-height=100}
-------------------------------------------------------

### **Fazit**
Natürlich gäbe es noch mehr Möglichkeiten, in dem man beispielsweise eine Stichprobe der Größe *n* in die Werkstatt schickt und den Rest so fahren lässt, es zeigt sich aber doch sehr deutlich, wie kostenintensiv solche Problematiken ohne Datenanalytik werden können. <br><br>
Vertraut Scania auf die getroffenen Vorhersagen, so entstehen Gesamtkosten von ca. 9170, schickt die Firma alle LKW's in die Werkstatt, entstehen schnell Kosten von über 156000. <br><br>
Der Aspekt *Predictive Maintenance* zur Kostenminimierung ist also ein essenzieller Bestandteil moderner Unternehmen und aus dem Handwerkskasten der Statistiker und Analytiker nicht mehr wegzudenken.

Über Uns {data-orientation=rows}
=======================================================

<u>Über die eoda GmbH:</u> <br>
eoda ist ein auf Data Science spezialisiertes IT-Unternehmen. Das Portfolio umfasst Consulting, Analytic Services, Software und Training. Die Leistungen erstrecken sich dabei über den gesamten Workflow vom Datenmanagement über die Analyse und Interpretation der Ergebnisse bis hin zur Integration von Analyse-Workflows in bestehende Prozesse und Applikationen. Das interdisziplinäre Team von eoda kombiniert fundiertes Wissen über Geschäftsprozesse mit der kompetenten Anwendung der passenden statistischen Analyseverfahren.

Als Pionier in Deutschland für die Open Source Programmiersprache R bietet eoda ein umfassendes Portfolio für den produktiven Einsatz von R. Spark, AI-Frameworks wie tensorflow oder MxNet und andere Data-Science-Sprachen wie Python und Julia vervollständigen unser Toolkit und helfen uns, die täglichen Herausforderungen von Data Science zu meistern.

eoda bietet ein ganzheitliches Trainings- und Qualifizierungskonzept für R und Python. Wir bieten Schulungen in deutscher und englischer Sprache an.

Für weitere Informationen, kontaktieren Sie uns über:
<center><a href="www.eoda.de">www.eoda.de</a></center>

<br><br><br><br><br><br><br><br>

<u>About eoda GmbH:</u> <br>
eoda is an IT company specialized in data science. Its portfolio comprises consulting, analytic services, software and training. The services cover the entire workflow from data acquisition to analysis to the interpretation of results and the integration of analysis workflows into existing processes and applications. The interdisciplinary team of eoda combines a profound knowledge of business processes with a competent usage of suitable methods for statistical analysis.

As a pioneer in Germany for the open source statistical language R, eoda provides a comprehensive portfolio for the productive application of R. The use of spark, AI frameworks like tensorflow or MxNet and other data science languages like Python and Julia complete our toolkit and help us master the daily challenges of data science.

eoda provides a unique holistic training and qualification concept for R and Python. We can provide trainings in both German and English.

For further information, contact us on:
<center><a href = "www.eoda.de">www.eoda.de</a></center>

<br><br><br><br><br><br><br><br><br>

<center><img src = "eoda_logo.png" alt = "Logo" height = "35%" width = "35%"></center>


```{r new_model, eval = FALSE}
control_cv_five_ten <- trainControl(method = "repeatedcv",
                                        number = 5,
                                        repeats = 10,
                                        allowParallel = TRUE,
                                        classProbs = TRUE,
                                        verboseIter = TRUE,
                                        summaryFunction = mnLogLoss)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)

grid_knn_mtry10 <- expand.grid(mtry = 10, splitrule = "gini", min.node.size = 1)



system.time(
  model_mtry10 <- train(class ~ .,
                               data = data_trucks_knn_training,
                               method = "ranger",
                               metric = "logLoss",
                               importance = "impurity",
                               verbose = TRUE,
                               trControl = control_cv_five_ten,
                               tuneGrid = grid_knn_mtry10,
                               num.trees = 1000)
)

grid_knn_mtry17 <- expand.grid(mtry = 17, splitrule = "gini", min.node.size = 1)



system.time(
  model_mtry17 <- train(class ~ .,
                               data = data_trucks_knn_training,
                               method = "ranger",
                               metric = "logLoss",
                               importance = "impurity",
                               verbose = TRUE,
                               trControl = control_cv_five_ten,
                               tuneGrid = grid_knn_mtry17,
                               num.trees = 1000)
)

grid_knn_mtry20 <- expand.grid(mtry = 20, splitrule = "gini", min.node.size = 1)



system.time(
  model_mtry20 <- train(class ~ .,
                               data = data_trucks_knn_training,
                               method = "ranger",
                               metric = "logLoss",
                               importance = "impurity",
                               verbose = TRUE,
                               trControl = control_cv_five_ten,
                               tuneGrid = grid_knn_mtry20,
                               num.trees = 1000)
)

stopCluster(cluster)
registerDoSEQ()
```

```{r eval_mtry10, eval = FALSE}
pred_mtry10 <- predict(model_mtry10, data_trucks_knn_test, type = "prob")

threshold_mtry10 <- min_cost_func(seq(from = 0.95, to = 0.96, length.out = 100), pred_mtry10, data_trucks_knn_test)
min_cost_place_mtry10 <- which(threshold_mtry10$cost == min(threshold_mtry10$cost))[1]
min_threshold_mtry10 <- threshold_mtry10$threshold[min_cost_place_mtry10]
min_cost_mtry10 <- threshold_mtry10$cost[min_cost_place_mtry10]
ggplot(threshold_mtry10, aes(x = threshold_mtry10$threshold, y = threshold_mtry10$cost)) +
  geom_line()
```

```{r eval_mtry17, eval = FALSE}
pred_mtry17 <- predict(model_mtry17, data_trucks_knn_test, type = "prob")

threshold_mtry17 <- min_cost_func(seq(from = 0.95, to = 0.96, length.out = 100), pred_mtry17, data_trucks_knn_test)
min_cost_place_mtry17 <- which(threshold_mtry17$cost == min(threshold_mtry17$cost))[1]
min_threshold_mtry17 <- threshold_mtry17$threshold[min_cost_place_mtry17]
min_cost_mtry17 <- threshold_mtry17$cost[min_cost_place_mtry17]
ggplot(threshold_mtry17, aes(x = threshold_mtry17$threshold, y = threshold_mtry17$cost)) +
  geom_line()
```

```{r eval_mtry20, eval = FALSE}
pred_mtry20 <- predict(model_mtry20, data_trucks_knn_test, type = "prob")

threshold_mtry20 <- min_cost_func(seq(from = 0.95, to = 0.975, length.out = 100), pred_mtry20, data_trucks_knn_test)
min_cost_place_mtry20 <- which(threshold_mtry20$cost == min(threshold_mtry20$cost))[1]
min_threshold_mtry20 <- threshold_mtry20$threshold[min_cost_place_mtry20]
min_cost_mtry20 <- threshold_mtry20$cost[min_cost_place_mtry20]
ggplot(threshold_mtry20, aes(x = threshold_mtry20$threshold, y = threshold_mtry20$cost)) +
  geom_line()
```
