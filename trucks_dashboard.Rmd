---
title: "Luftdrucksystemfehler bei Scania Trucks"
output: 
  flexdashboard::flex_dashboard:
    css: styles.css
    orientation: columns
    code_folding: hide
    vertical_layout: fill
---

```{r setup, eval = FALSE}
# library setup
library(flexdashboard)
library(magrittr)
library(dplyr)
library(caret)
library(purrr)
library(ggplot2)
library(stringr)
library(parallel)
library(doParallel)
library(knitr)
library(kableExtra)
library(rmarkdown)

# global options
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
options(scipen = 100)

# read csv data
data_trucks_training <- read.csv("aps_failure_training_set.csv", sep = ",", skip = 20, na.strings = "na")
data_trucks_test <- read.csv("aps_failure_test_set.csv", sep = ",", skip = 20, na.strings = "na")
```

Problematik
=======================================================================

Column {data-width=1}
-----------------------------------------------------------------------

### **Problemstellung** {data-height=700}
Der Scania-Trucks Datensatz kommt mit 171 anonymisierten Featuren sowie 76000 Observationen, welche im Verhältnis 60.000 zu 16.000 in Trainings- bzw. Testdaten aufgeteilt sind. Jede Observation enthält die Information, ob ein Fehler im Luftdruckssystem ( im Folgenden **LDS** genannt ) vorliegt oder nicht. <br><br>
Die Problemstellung lautet: <br>
<div class = "bordered">
*Sage für jede Observation im Testdatensatz voraus, ob ein Fehler im LDS vorliegt oder nicht. Minimiere dabei folgende Kostenfunktion:*
<br>
**$cost(FP, FN) = 10 \cdot FP + 500 \cdot FN$** <br>
*Es handelt sich hierbei also um ein **Klassifizierungsproblem**, mit der Kostenfunktion $cost(FP, FN)$ als Metrik.* <br>
</div> <br>
**<u>Fehler 1. Art (FP):</u>** <br>
Der Fehler 1. Art, hier **F**alse **P**ositive, bedeutet, dass man einer Observation einen Fehler im LDS zuschreibt, obwohl das Fahrzeug fehlerfrei ist. Man schickt das Fahrzeug also in die Werkstatt, obwohl kein Fehler vorhanden ist. <br><br>
**<u>Fehler 2. Art (FN):</u>** <br>
Der Fehler 2. Art, hier **F**alse **N**egative, bedeutet, dass man eine Observation als fehlerfrei einstuft, obwohl das Fahrezeug einen Fehler im LDS aufweist. <br><br>
<div class = "bordered">
*Der Fehler 1. Art ist logischerweise deutlich kostengünstiger gewichtet als der Fehler 2. Art. Es ist wesentlich günstiger einen LKW fälschlicherweise in die Werkstatt zur Überprüfung zu schicken, als dass ein LKW, bedingt durch einen **LDS-Fehler**, auf der Strecke liegen bleibt.*
</div> <br><br>

### **Hintergrund** {data-height=300}
Das Scania-Trucks Problem wurde auf der **IDA 2016** vorgestellt. Die IDA ist ein internationales Symposium über intelligente Datenanalyse, welche 2016 im Kontext des **maschinellen Lernens** das Industrieproblem für die Öffentlichkeit zugänglich gemacht hat. Scania, Mitsponsor der IDA, hat auf die beiden kostengünstigstens Modelle einen Preis von 500$ aussgeschrieben, sowie einen Rednerspot auf der **IDA** selbst. <br><br>

<div> <img src = "Scania.png" alt = "Scania Logo" height = "100%" " width = "100%"></div>

Column {data-width=3}
----------------------------------------------------------------------

###
<center>
<div style = "display: inline-block; height: 90vh; "> <img src = "Titelbild.png" alt = "Titel" height = "100%"  width = "100%"></div>
</center>

Datensatz {data-orientation=rows}
===============================================

Row {data-height=200}
-----------------------------------------------

### **Histogramm-Feature**
Aus der Beschreibung des Scania-Trucks Problems lässt sich herauslesen, dass gewisse Feature Histogrammdaten abbilden. 
Das heißt, dass ein Feature auf mehrere Container aufgeteilt ist, wobei der Wert im Container $A_i$ die Aufenthaltsdauer in der Klasse $i$ bedeutet und $A$ das obergeordnete Feature ist. <br>
Beispielverteilung der Feature **ag** & **ay**:

<div style = "display: inline;">

<div style = "display: inline-block; width: 48%;"> 
```{r table_hist_ag}
# Example-table for the histogramm-feature
kable(data_trucks_training[1:5, str_detect(colnames(data_trucks_training), "ag_00+") == TRUE], "html", caption = "Histogrammdaten ag") %>%
  kable_styling("striped")
```
</div>

<div style = "display: inline-block; width: 48%; margin-left: 15px;"> 
```{r table_hist_ay}
# Example-table for the histogramm-feature
kable(data_trucks_training[1:5, str_detect(colnames(data_trucks_training), "ay_00+") == TRUE], "html", caption = "Histogrammdaten ay") %>%
  kable_styling("striped")
```
</div>

</div>

Row {data-height=300 .tabset .tabset-fade}
-----------------------------------------------

### Feature **ag**

```{r mean_hist_ag}
# calculate mean distribution for the ag feature
ag_labels <- paste0("ag_00", 0:9)
ag_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "ag_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
ag_mean_df <- data.frame(labels = ag_labels, mean = ag_mean)
```


<div style = "display: inline-block; width: 90vw;">

<div style = "float: left; margin-top: 20px;">
```{r plot_ag, out.width = "95%", fig.height = 3}
# plot ag distribution
ggplot(ag_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 49%; margin-top: 70px;">
```{r table_ag, out.width = "95%"}
ag_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "ag_000"):which(colnames(data_trucks) == "ag_009")]
for(i in 1:10) {
  ag_summary <- rbind(ag_summary, summary(sub_data_trucks[[i]]))
}
ag_summary <- cbind("Var" = paste0("ag_00", 0:9), ag_summary)
kable(ag_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>
### Feature **ay**

```{r mean_hist_ay}
# calculate mean distribution for the ay feature
ay_labels <- paste0("ay_00", 0:9)
ay_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "ay_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
ay_mean_df <- data.frame(labels = ay_labels, mean = ay_mean)
```


<div style = "display: inline-block; width: 100%;">

<div style = "float: left; margin-top: 20px;">
```{r plot_ay, out.width = "95%", fig.height = 3}
# plot ay distribution
ggplot(ay_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 49%; margin-top: 70px;">
```{r table_ay, out.width = "95%"}
ay_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "ay_000"):which(colnames(data_trucks) == "ay_009")]
for(i in 1:10) {
  ay_summary <- rbind(ay_summary, summary(sub_data_trucks[[i]]))
}
ay_summary <- cbind("Var" = paste0("ay_00", 0:9), ay_summary)
kable(ay_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>

### Feature **az**

```{r mean_hist_az}
# calculate mean distribution for the az feature
az_labels <- paste0("az_00", 0:9)
az_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "az_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
az_mean_df <- data.frame(labels = az_labels, mean = az_mean)
```


<div style = "display: inline-block; width: 100%;">

<div style = "float: left; margin-top: 20px;">
```{r plot_az, out.width = "95%", fig.height = 3}
# plot az distribution
ggplot(az_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 49%; margin-top: 70px;">
```{r table_az, out.width = "95%"}
az_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "az_000"):which(colnames(data_trucks) == "az_009")]
for(i in 1:10) {
  az_summary <- rbind(az_summary, summary(sub_data_trucks[[i]]))
}
az_summary <- cbind("Var" = paste0("az_00", 0:9), az_summary)
kable(az_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>

### Feature **ba**

```{r mean_hist_ba}
# calculate mean distribution for the ba feature
ba_labels <- paste0("ba_00", 0:9)
ba_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "ba_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
ba_mean_df <- data.frame(labels = ba_labels, mean = ba_mean)
```


<div style = "display: inline-block; width: 100%;">

<div style = "float: left; margin-top: 20px;">
```{r plot_ba, out.width = "95%", fig.height = 3}
# plot ba distribution
ggplot(ba_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 49%; margin-top: 70px;">
```{r table_ba, out.width = "95%"}
ba_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "ba_000"):which(colnames(data_trucks) == "ba_009")]
for(i in 1:10) {
  ba_summary <- rbind(ba_summary, summary(sub_data_trucks[[i]]))
}
ba_summary <- cbind("Var" = paste0("ba_00", 0:9), ba_summary)
kable(ba_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>

### Feature **cn**

```{r mean_hist_cn}
# calculate mean distribution for the cn feature
cn_labels <- paste0("cn_00", 0:9)
cn_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "cn_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
cn_mean_df <- data.frame(labels = cn_labels, mean = cn_mean)
```


<div style = "display: inline-block; width: 100%;">

<div style = "float: left; margin-top: 20px;">
```{r plot_cn, out.width = "95%", fig.height = 3}
# plot cn distribution
ggplot(cn_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 49%; margin-top: 70px;">
```{r table_cn, out.width = "95%"}
cn_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "cn_000"):which(colnames(data_trucks) == "cn_009")]
for(i in 1:10) {
  cn_summary <- rbind(cn_summary, summary(sub_data_trucks[[i]]))
}
cn_summary <- cbind("Var" = paste0("cn_00", 0:9), cn_summary)
kable(cn_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>

### Feature **cs**

```{r mean_hist_cs}
# calculate mean distribution for the cs feature
cs_labels <- paste0("cs_00", 0:9)
cs_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "cs_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
cs_mean_df <- data.frame(labels = cs_labels, mean = cs_mean)
```


<div style = "display: inline-block; width: 100%;">

<div style = "float: left; margin-top: 20px;">
```{r plot_cs, out.width = "95%", fig.height = 3}
# plot cs distribution
ggplot(cs_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 49%; margin-top: 70px;">
```{r table_cs, out.width = "95%"}
cs_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "cs_000"):which(colnames(data_trucks) == "cs_009")]
for(i in 1:10) {
  cs_summary <- rbind(cs_summary, summary(sub_data_trucks[[i]]))
}
cs_summary <- cbind("Var" = paste0("cs_00", 0:9), cs_summary)
kable(cs_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>

### Feature **ee**

```{r mean_hist_ee}
# calculate mean distribution for the ee feature
ee_labels <- paste0("ee_00", 0:9)
ee_mean <- sapply(data_trucks_training[, str_detect(colnames(data_trucks_training), "ee_00+") == TRUE], function(x) mean(x, na.rm = TRUE)) %>% as.numeric()
ee_mean_df <- data.frame(labels = ee_labels, mean = ee_mean)
```

<div style = "display: inline-block; width: 100%;">

<div style = "float: left; margin-top: 20px;">
```{r plot_ee, out.width = "95%", fig.height = 3}
# plot ee distribution
ggplot(ee_mean_df, aes(x = labels, y = mean)) +
  geom_bar(stat = "identity", fill = "#88ab33") +
  theme_minimal() +
  ggtitle("Verteilung des Mittelwertes") +
  xlab("") + ylab("")
```
</div>

<div style = "display: inline-block; float: left; width: 49%; margin-top: 70px;">
```{r table_ee, out.width = "95%"}
ee_summary <- c()
sub_data_trucks <- data_trucks[which(colnames(data_trucks) == "ee_000"):which(colnames(data_trucks) == "ee_009")]
for(i in 1:10) {
  ee_summary <- rbind(ee_summary, summary(sub_data_trucks[[i]]))
}
ee_summary <- cbind("Var" = paste0("ee_00", 0:9), ee_summary)
kable(ee_summary %>% as.data.frame(row.names = TRUE) %>% mutate_at(-1, funs(as.character(.) %>% as.numeric())), "html", digits = 2) %>%
  kable_styling("striped", full_width = TRUE)
```
</div>

</div>

Feature-Engineering
=========================================

Column {data-width=100}
-----------------------------------------

### **NA-Analyse**

Der Scania-Trucks Datensatz weist eine hohe Zahl an fehlenden Werten ( hier im Folgenden **NA's** genannt) auf. Dies kann insbesondere beim modellieren zu Problemen führen, da fehlende Werte für den **Klassifizierungsalgorithmus** unmöglich zu behandeln sind. <br>
Eine Möglichkeit besteht darin, eine gewisse Anzahl an NA's zuzulassen und dementsprechend die Anzahl der Feature zu reduzieren. Alle Observationen, welche nach der **Featurereduktion** noch NA's enthalten, werden entfernt. <br>
Folgende Tabelle liefert einen Überblick über die **NA Grenzen**: 

```{r NA_data_frame, eval = FALSE}
# setup the whole dataset
data_trucks <- rbind(data_trucks_training, data_trucks_test)

# generate data frame for the na boundaries
na_df <- data.frame(Var = colnames(data_trucks), 
                    Na = sapply(data_trucks, function(x) sum(is.na(x))))

# get unique na breakpoints for all features
na_breaks <- na_df$Na %>% unique() %>% sort()

result_NA <- data_frame(na_number = na_breaks, vars = numeric(length = length(na_breaks)),
                        obs = numeric(length = length(na_breaks)),
                        obs_pos = numeric(length(na_breaks)))
# calculate the feature_gain / observation_loss for all na boundaries
for (i in na_breaks){
  
  select_columns <- 
    which(na_df$Na <= i) %>% 
    as.numeric()
  
  sub_trucks <- data_trucks[ , select_columns] %>% na.omit()
  
  n_obs <- nrow(sub_trucks)
  n_vars <- ncol(sub_trucks)
  n_obs_pos <- sub_trucks[sub_trucks$class == "pos", ] %>% count() %>% as.numeric()
  
  result_NA$vars[result_NA$na_number == i] = n_vars
  result_NA$obs[result_NA$na_number == i] = n_obs
  result_NA$obs_pos[result_NA$na_number == i] = n_obs_pos
}

# get the relative gain / loss
result_NA <- result_NA %>%
  mutate(vars_percent = (vars / ncol(data_trucks)) * 100, 
         obs_percent = (obs / nrow(data_trucks)) * 100,
         obs_pos_percent = (obs_pos / nrow(data_trucks[data_trucks$class == "pos", ])) * 100)
```

<br>

```{r NA_table}
# print table for the na boundaries
kable(result_NA %>% head(5), "html", caption = "NA Grenzen, Featureanzahl ( Grün ), allgemeiner Obsservationsverlust ( Orange ) & fehlerhafter Observationsverlust ( Blau )") %>%
  kable_styling("striped") %>%
  column_spec(c(2,5), background = "#88ab33", color = "white") %>%
  column_spec(c(3,6), background = "#F98948", color = "white") %>%
  column_spec(c(4,7), background = "#437F97", color = "white") 
```

<br>

<center>
```{r NA_plot}
# plot the na boundaries respective to the gain / loss
ggplot(result_NA) + 
  geom_point(aes(na_number, vars_percent), color = "#88ab33") +
  geom_point(aes(na_number, obs_percent), color = "#F98948") +
  geom_point(aes(na_number, obs_pos_percent), color = "#437F97") +
  xlab("NA Anzahl") + ylab("") +
  scale_y_continuous(limits = c(1, 100)) 
```
</center>


<br>

<div class = "bordered">
<center>**Featuregewinnung:**</center> <br>
Aus der Tabelle lässt sich erkennen, dass bei den unterschiedlichen NA-Grenzen die Anzahl an **gewonnener Feature** stark schwankt. So gewinnt man beim Sprung von 0 auf 195 NA's lediglich 1 Feature dazu, beim Sprung von 861 auf 863 Feature aber direkt 30 Feature. Das **NA-Verhalten** ist also alles andere als proportional. <br>
Die Entscheidung, welche NA-Grenze man als Auschlussverfahren nimmt, hängt aber nicht nur von der Featuregewinnung ab.
</div> <br>
<div class = "bordered">
<center>**Allgemeiner Observationsverlust:**</center> <br>
Alle Feature im späteren Modell zu berücksichten würde nichts bringen, wenn man nur noch auf 5% der ursprünglichen Daten trainieren kann. Deshalb spielt der **Observationsverlust** eine starke Rolle in der Entscheidung. Hier zeichnet sich ein starker Sprung von 5598 auf 12012 NA's ab. Evaluiert man also die Grenzen anhand des Observationsverlustes, sollte man nicht über die Grenze von 5598 hinaus gehen, da direkt danach c.a. 10% der LKW's zusätzlich verloren gehen. 
</div> <br>
Normalerweise wären dass bereits ausreichend Informationen, um eine fundierte Meinung über die Wahl der NA-Grenze zu treffen. Der Scania-Trucks Datensatz weist allerdings ein noch größeres Problem auf. Von den 76000 Observationen sind lediglich **1375** fehlerhaft. Dadurch könnte es passieren, dass wir bei der Wahl der NA-Grenze alle fehlerhaften Observationen verlieren. <br>
Demnach muss zusätzlich folgende Variable mit einkalkuliert werden: <br><br>
<div class = "bordered">
<center>**Fehlerhafter Observationsverlust:**</center> <br>
Der fehlerhafte Oberservationsverlust beschreibt die Anzahl der Observationen die bei der Wahl der NA-Grenze verloren gehen und zusätzlich einen Fehler im LDS aufweisen. Anhand der geringen Fehlerrate im Datensatz wäre es fatal, zu viele der fehlerhaften Fahrzeuge zu verlieren, da ein Modell so möglicherweise auf ausschließlich fehlerfreien Daten trainieren könnte. Die Grenze für fehlerhafte Observationen findet sich in der Tabelle offensichtlich beim Sprung von 928 NA's auf 3188 NA's. Obwohl man hier nur 1 Feature dazu gewinnen würde, fallen 30% der fehlerhaften Observationen dadurch raus. Die Grenze ist demnach also bei 928 NA's zu setzen.
</div> </br>
<center>**<u>Fazit:</u>**</center>
Die NA-Analyse zeigt, dass verschiedene Breakpoints existieren, um eine gewisse Anzahl von Featuren zu erhalten / nicht zu viele Observationen zu verlieren. Um auf dem kompletten Trainingsset vorhersagen treffen zu können, müssen die fehlenden Werte aber aufgefüllt werden, anstatt **NA-Reduktion** zu betreiben. Hierzu stehen Möglichkeiten wie beispielsweise die **knn-imputation** zur Verfügung. Im Folgenden wird diese Möglichkeiten evaluiert.




Column {data-width=100}
-----------------------------------------

### **Datenaufbereitung ( Relativierung )**


Die **Datensatzanalyse** hat gezeigt, dass viele der Histogrammdaten nicht gleichmäßig ( normal- ) verteilt sind.
Oftmals sind Container eines Histogrammfeatures für fast alle Observationen 0, andere Containere hingegen sind mit den unterschiedlichsten Größenordnungen von Zahlen gefüllt. <br>
Hinzu kommt, dass die Werte in den verschiedenen Containern **absolute** Daten sind, das heißt: <br><br>
<center>
<div class = "bordered" style = "width: 30vw; font-size: 20px;">
**$\sum_{i = 0}^{9}{A_i}$** <br><br>
ist **nicht notwendigerweise gleich** für alle Observationen.
</div> 
</center>

<br>

Um das Problem der absoluten Histogrammdaten zu beseitigen ist es sinnvoll diese zu **relativieren**. Man stellt also jeden absoluten Wert $i$ in **prozentuellen Bezug** zu der **Gesamtaufenthaltszeit** jeder Observation in der Klasse $A$. <br>
Dadurch ergibt sich folgende Formel für die neuen Werte $\tilde{A}$: <br><br>
<center>
<div class = "bordered" style = "font-size: 20px; width: 30vw;">
**$\tilde{A}_i = \frac{A_i}{\sum_{i = 0}^{9}{A_i}}  mit  \sum_{i = 0}^{9}{\tilde{A}_i} = 1$** <br><br>
für **jede** Observation.
</div>
</center>
<br>

**<u>Vorher:</u>** <br>

```{r hist_ag_before_table}
# example table of the histogramm feature  ag before qualifying the data
kable(data_trucks_training[1:5, str_detect(colnames(data_trucks_training), "ag_00+") == TRUE], "html", caption = "Histogrammdaten") %>%
  kable_styling("striped")
```

```{r histogramm_percentage, eval = FALSE}
# qualify the histogramm data
data_trucks_perc <- data_trucks %>%
  mutate(
    perc_ag_0 = ag_000 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_1 = ag_001 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_2 = ag_002 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_3 = ag_003 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_4 = ag_004 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_5 = ag_005 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_6 = ag_006 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_7 = ag_007 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_8 = ag_008 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ag_9 = ag_009 / (ag_000 + ag_001 + ag_002 + ag_003 + ag_004 + ag_005 + ag_006 + ag_007 + ag_008 + ag_009),
    perc_ay_0 = ay_000 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_1 = ay_001 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_2 = ay_002 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_3 = ay_003 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_4 = ay_004 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_5 = ay_005 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_6 = ay_006 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_7 = ay_007 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_8 = ay_008 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_ay_9 = ay_009 / (ay_000 + ay_001 + ay_002 + ay_003 + ay_004 + ay_005 + ay_006 + ay_007 + ay_008 + ay_009),
    perc_az_0 = az_000 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_1 = az_001 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_2 = az_002 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_3 = az_003 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_4 = az_004 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_5 = az_005 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_6 = az_006 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_7 = az_007 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_8 = az_008 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_az_9 = az_009 / (az_000 + az_001 + az_002 + az_003 + az_004 + az_005 + az_006 + az_007 + az_008 + az_009),
    perc_ba_0 = ba_000 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_1 = ba_001 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_2 = ba_002 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_3 = ba_003 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_4 = ba_004 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_5 = ba_005 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_6 = ba_006 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_7 = ba_007 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_8 = ba_008 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_ba_9 = ba_009 / (ba_000 + ba_001 + ba_002 + ba_003 + ba_004 + ba_005 + ba_006 + ba_007 + ba_008 + ba_009),
    perc_cn_0 = cn_000 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_1 = cn_001 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_2 = cn_002 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_3 = cn_003 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_4 = cn_004 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_5 = cn_005 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_6 = cn_006 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_7 = cn_007 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_8 = cn_008 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cn_9 = cn_009 / (cn_000 + cn_001 + cn_002 + cn_003 + cn_004 + cn_005 + cn_006 + cn_007 + cn_008 + cn_009),
    perc_cs_0 = cs_000 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_1 = cs_001 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_2 = cs_002 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_3 = cs_003 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_4 = cs_004 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_5 = cs_005 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_6 = cs_006 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_7 = cs_007 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_8 = cs_008 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_cs_9 = cs_009 / (cs_000 + cs_001 + cs_002 + cs_003 + cs_004 + cs_005 + cs_006 + cs_007 + cs_008 + cs_009),
    perc_ee_0 = ee_000 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_1 = ee_001 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_2 = ee_002 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_3 = ee_003 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_4 = ee_004 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_5 = ee_005 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_6 = ee_006 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_7 = ee_007 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_8 = ee_008 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009),
    perc_ee_9 = ee_009 / (ee_000 + ee_001 + ee_002 + ee_003 + ee_004 + ee_005 + ee_006 + ee_007 + ee_008 + ee_009)
  )

data_trucks_perc <- data_trucks_perc[, !str_detect(names(data_trucks_perc), "ag_00+|ay_00+|az_00+|ba_00+|cn_00+|cs_00+|ee_00+")]
```

<br>

**<u>Nachher:</u>** <br>

```{r hist_ag_after_table}
# example table of the histogramm feature ag after qualifying the data
kable(data_trucks_perc[1:5, str_detect(colnames(data_trucks_perc), "perc_ag_+") == TRUE], "html", caption = "Histogrammdaten") %>%
  kable_styling("striped", position = "left" )
```

Column {data-width=100}
-----------------------------------------

### **Pre-Processing**

```{r Pre-Process, eval = FALSE}
# setup the knn imputation
data_trucks_knn <- preProcess(data_trucks_perc, method = "knnImpute")

data_trucks_knn_training <- predict(data_trucks_knn, data_trucks_perc[1:60000, ])
data_trucks_knn_test <- predict(data_trucks_knn, data_trucks_perc[60001:76000, ])
```

Zusätzlich zu seinen Histogrammdaten verfügt der Datensatz über, wie bereits erwähnt, eine vielzahl von **NA's** ( fehlende Werte ).
Diese würden bereits beim trainieren der Modelle für Probleme sorgen, da der **Algorithmus** mit diesen Daten nicht arbeiten kann ( keine Splits setzen, Regressionskoeffizienten berechnen, etc. ). <br>
Eine Möglichkeit bietet hier die **knn-Imputation** ( *k-nächste-Nachbarn-Schätzung* ). <br><br>
Die Schätzung erfolgt in **3** Schritten. <br>
<center>
<font size = "13px"><font color = "#88ab33">Zentrieren</font>, <font color = "#F98948">Skalieren</font> & <font color = "#437F97">Schätzen</font></font>
</center>
<br>
Folgende Tabellenausschnitte verdeutlicht diese Schritte: <br><br>

<div style = "display: inline;">

<div style = "display: inline-block; width: 49%;">
```{r standard_table}
# example table before preProcessing 
kable(data_trucks[["ad_000"]] %>% head(5), "html") %>%
  kable_styling("striped") 
```
</div>

<div style = "display: inline-block; width: 49%;">
```{r center_table}
# example table after centering
kable((data_trucks[["ad_000"]] - mean(data_trucks[["ad_000"]], na.rm = TRUE)) %>% head(5), "html") %>%
  kable_styling("striped") %>%
  column_spec(1, background = "#88ab33", color = "white")
```
</div>

</div>

<div style = "display: inline;">

<div style = "display: inline-block; width: 49%;">
```{r scale_table}
# example table after centering and scaling
kable(((data_trucks[["ad_000"]] - mean(data_trucks[["ad_000"]], na.rm = TRUE)) / sd(data_trucks[["ad_000"]], na.rm = TRUE)) %>% head(5), "html") %>%
  kable_styling("striped") %>% 
  column_spec(1, background = "#F98948", color = "white")
```
</div>

<div style = "display: inline-block; width: 49%">
```{r impute_table}
# example table after centering, scaling and knn imputation
kable(data_trucks_knn_training[["ad_000"]] %>% head(5), "html") %>%
  kable_styling("striped") %>%
  column_spec(1, background = "#437F97", color = "white")
```
</div>

</div>



Modellierung
===============================

```{r evaluation_functions, eval = FALSE}
# helperfunctions for cost evaluation and sensitivity / specificity calculation for given thresholds
sensspec_rate <- function(threshold, predicted_set, test_set) {
  predicted_class <- ifelse(predicted_set$neg > threshold, "neg", "pos")
  return(confusionMatrix(predicted_class, test_set$class)$table %>% data.frame() %>% extract2("Freq"))
}

min_cost_func <- function(threshold_vec, predicted_set, test_set) {
  false_negatives <- sapply(threshold_vec, function(x) sensspec_rate(x, predicted_set, test_set)[3])
  false_positives <- sapply(threshold_vec, function(x) sensspec_rate(x, predicted_set, test_set)[2])

  threshold_df <- data.frame(threshold = threshold_vec,
                             false_positives = false_positives,
                             false_negatives = false_negatives)
  
  threshold_df <- threshold_df %>%
    mutate(
      cost = false_positives * 10 + false_negatives * 500
    )
  
  return(threshold_df)
}
```


Column {data-width=100}
------------------------------

### **Modellauswahl & Güte**

Zur Lösung des **Klassifizierungsproblems** wird ein **Random-Forest-Modell** verwendet. Als **Parameterraster** werden folgende Werte benutzt:
<div class = "bordered">
<center>$mtry = \sqrt{171} \approx 13$</center> <br>
*Als **mtry** verwenden die Modelle den Standardwert aus $\sqrt{Anzahl \space der \space Feature}$.* <br><br>
<center>$splitrule = gini$</center> <br>
*Als **splitrule** verwenden die Modelle den **Gini-Index** für Klassifikationsprobleme.*
</div> 

<br><br>


<center>**<u>Modell 1:</u> 10-fache, 5-faltige Kreuzvalidierung mit 500 Bäumen**</center> <br>

```{r rf_model_cv10_0.5k, eval = FALSE}
# model 2 - random forest with 10 times 5 folded cross validation and 500 trees
control_knn_cv_five_ten <- trainControl(method = "repeatedcv",
                                        number = 5,
                                        repeats = 10,
                                        allowParallel = TRUE,
                                        classProbs = TRUE,
                                        verboseIter = TRUE,
                                        summaryFunction = mnLogLoss)

grid_knn <- expand.grid(mtry = 13, splitrule = "gini", min.node.size = 1)

cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)

system.time(
  model_knn_cv10_0.5k <- train(class ~ .,
                               data = data_trucks_knn_training,
                               method = "ranger",
                               metric = "logLoss",
                               importance = "impurity",
                               verbose = TRUE,
                               trControl = control_knn_cv_five_ten,
                               tuneGrid = grid_knn,
                               num.trees = 500)
)

stopCluster(cluster)
registerDoSEQ()

```

```{r evaluation_cv10_0.5k, eval = FALSE}
# get optimal classificationthreshold to minimize the cost function for model 2
pred_cv10_0.5k <- predict(model_knn_cv10_0.5k, data_trucks_knn_test, type = "prob")

threshold_df_cv10_0.5k <- min_cost_func(seq(from = 0.93, to = 0.95, length.out = 100), pred_cv10_0.5k, data_trucks_knn_test)
min_cost_place_cv10_0.5k <- which(threshold_df_cv10_0.5k$cost == min(threshold_df_cv10_0.5k$cost))[1]
min_threshold_cv10_0.5k <- threshold_df_cv10_0.5k$threshold[min_cost_place_cv10_0.5k]
min_cost_cv10_0.5k <- threshold_df_cv10_0.5k$cost[min_cost_place_cv10_0.5k]
ggplot(threshold_df_cv10_0.5k, aes(x = threshold_df_cv10_0.5k$threshold, y = threshold_df_cv10_0.5k$cost)) +
  geom_line()
pred_cv10_0.5k_class <- ifelse(pred_cv10_0.5k$neg >= min_threshold_cv10_0.5k, "neg", "pos")
```

<div style = "display: inline;">

<div style = "display: inline-block; vertical-align: text-top;">
```{r confusion_cv10_0.5k_display}
# display the confusion Matrix of model 2
confusionMatrix(pred_cv10_0.5k_class, data_trucks_knn_test$class)
```
</div>
<div style = "display: inline-block; vertical-align: text-top;">
```{r model_cv10_0.5k_display}
# display model 2
model_knn_cv10_0.5k
```
<center>
<br>
<u>***Ergebnis:***</u> <br><br>
***Kosten:** `r min_cost_cv10_0.5k`* <br><br>
***Kosten pro LKW:** `r min_cost_cv10_0.5k / nrow(data_trucks_knn_test)`*
</center>
</div>

</div>

<br><br>

<center>**<u>Modell 2:</u> 10-fache, 5-faltige Kreuzvalidierung mit 1000 Bäumen**</center> <br>

```{r rf_model_cv10_1k, eval = FALSE}
# model 3 - random forest with 10 times 5 folded cross validation with 1000 trees
control_knn_cv_five_ten <- trainControl(method = "repeatedcv",
                                        number = 5,
                                        repeats = 10,
                                        allowParallel = TRUE,
                                        classProbs = TRUE,
                                        verboseIter = TRUE,
                                        summaryFunction = mnLogLoss)

grid_knn <- expand.grid(mtry = 13, splitrule = "gini", min.node.size = 1)

cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)

system.time(
  model_knn_cv10_1k <- train(class ~ .,
                             data = data_trucks_knn_training,
                             method = "ranger",
                             metric = "logLoss",
                             importance = "impurity",
                             verbose = TRUE,
                             trControl = control_knn_cv_five_ten,
                             tuneGrid = grid_knn,
                             num.trees = 1000)
)

stopCluster(cluster)
registerDoSEQ()

```

```{r evaluation_cv10_1k, eval = FALSE}
# get optimal classificationthreshold to minimize the cost function for model 3
pred_cv10_1k <- predict(model_knn_cv10_1k, data_trucks_knn_test, type = "prob")

threshold_df_cv10_1k <- min_cost_func(seq(from = 0.97, to = 0.98, length.out = 100), pred_cv10_1k, data_trucks_knn_test)
min_cost_place_cv10_1k <- which(threshold_df_cv10_1k$cost == min(threshold_df_cv10_1k$cost))[1]
min_threshold_cv10_1k <- threshold_df_cv10_1k$threshold[min_cost_place_cv10_1k]
min_cost_cv10_1k <- threshold_df_cv10_1k$cost[min_cost_place_cv10_1k]
ggplot(threshold_df_cv10_1k, aes(x = threshold_df_cv10_1k$threshold, y = threshold_df_cv10_1k$cost)) +
  geom_line()
pred_cv10_1k_class <- ifelse(pred_cv10_1k$neg >= min_threshold_cv10_1k, "neg", "pos")
```

<div style = "display: inline;">

<div style = "display: inline-block; vertical-align: text-top;">
```{r confusion_cv10_1k_display}
# display confusion Matrix of model 3
confusionMatrix(pred_cv10_1k_class, data_trucks_knn_test$class)
```
</div>
<div style = "display: inline-block; vertical-align: text-top;">
```{r model_cv10_1k_display}
# display model 3
model_knn_cv10_1k
```
<center>
<br>
<u>***Ergebnis:***</u> <br><br>
***Kosten:** `r min_cost_cv10_1k`* <br><br>
***Kosten pro LKW:** `r min_cost_cv10_1k / nrow(data_trucks_knn_test)`*
</center>
</div>

</div>

<br><br>

<center>**<u>Modell 3:</u> 10-fache, 5-faltige Kreuzvalidierung mit 2500 Bäumen**</center> <br>

```{r rf_model_cv10_2.5k, eval = FALSE}
# model 4- random forest with 10 times 5 folded cross validation with 2500 trees
control_knn_cv_five_ten <- trainControl(method = "repeatedcv",
                                        number = 5,
                                        repeats = 10,
                                        allowParallel = TRUE,
                                        classProbs = TRUE,
                                        verboseIter = TRUE,
                                        summaryFunction = mnLogLoss)

grid_knn <- expand.grid(mtry = 13, splitrule = "gini", min.node.size = 1)

cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)

system.time(
  model_knn_cv10_2.5k <- train(class ~ .,
                               data = data_trucks_knn_training,
                               method = "ranger",
                               metric = "logLoss",
                               importance = "impurity",
                               verbose = TRUE,
                               trControl = control_knn_cv_five_ten,
                               tuneGrid = grid_knn,
                               num.trees = 2500)
)

stopCluster(cluster)
registerDoSEQ()

```

```{r evaluation_cv10_2.5k, eval = FALSE}
# get optimal classification threshold to minimize the cost function for model 4
pred_cv10_2.5k <- predict(model_knn_cv10_2.5k, data_trucks_knn_test, type = "prob")

threshold_df_cv10_2.5k <- min_cost_func(seq(from = 0.95, to = 0.96, length.out = 100), pred_cv10_2.5k, data_trucks_knn_test)
min_cost_place_cv10_2.5k <- which(threshold_df_cv10_2.5k$cost == min(threshold_df_cv10_2.5k$cost))[1]
min_threshold_cv10_2.5k <- threshold_df_cv10_2.5k$threshold[min_cost_place_cv10_2.5k]
min_cost_cv10_2.5k <- threshold_df_cv10_2.5k$cost[min_cost_place_cv10_2.5k]
ggplot(threshold_df_cv10_2.5k, aes(x = threshold_df_cv10_2.5k$threshold, y = threshold_df_cv10_2.5k$cost)) +
  geom_line()
```

<div style = "display: inline;">

<div style = "display: inline-block; vertical-align: text-top;">
```{r confusion_cv10_2.5k_display}
# display confusion Matrix of model 4
confusionMatrix(pred_cv10_2.5k_class, data_trucks_knn_test$class)
```
</div>
<div style = "display: inline-block; vertical-align: text-top;">
```{r model_cv10_2.5k_display}
# display model 4
model_knn_cv10_1k
```
<center>
<br>
<u>***Ergebnis:***</u> <br><br>
***Kosten:** `r min_cost_cv10_2.5k`* <br><br>
***Kosten pro LKW:** `r min_cost_cv10_2.5k / nrow(data_trucks_knn_test)`*
</center>
</div>

</div>

Column {data-width=100}
------------------------------

### **Variablenwichtigkeit & Laufzeit**

<center>**<u>Specs:</u>**</center>

<center>
*Intel(R) Core(TM) i5-6200U CPU @ 2.30GHz, 2400 MHz, 2 Kerne, 4 logische Prozessoren, 8GB RAM* <br>
*Gerechnet wurde auf 3 Prozessoren*
</center>

<br>



<center>**<u>Modell 1:</u>**</center> <br>

```{r variable-_importance_cv10_0.5k, eval = FALSE}
# get variable importance of model 2
var_imp_df_cv10_0.5k <- data.frame(Variable = rownames(varImp(model_knn_cv10_0.5k)[[1]]), Importance = varImp(model_knn_cv10_0.5k)[[1]]$Overall,
                                  Rank = rank(varImp(model_knn_cv10_0.5k)[[1]]$Overall)) %>%
  arrange(desc(Rank))
```

```{r var_imp_cv10_0.5k_table}
# display variable importance of model 2
kable(var_imp_df_cv10_0.5k[, 1:2] %>% head(5), "html") %>%
  kable_styling("striped")
```

<center>**$Laufzeit \approx 1 \space Stunde \space 11 \space Minuten$**</center>

<br><br>

<center>**<u>Modell 2:</u>**</center> <br>

```{r variable_importance_cv10_1k, eval = FALSE}
# get variable importance of model 3
var_imp_df_cv10_1k <- data.frame(Variable = rownames(varImp(model_knn_cv10_1k)[[1]]), Importance = varImp(model_knn_cv10_1k)[[1]]$Overall,
                                  Rank = rank(varImp(model_knn_cv10_1k)[[1]]$Overall)) %>%
  arrange(desc(Rank))
```

```{r var_imp_cv10_1k_table}
# display variable importance of model 3
kable(var_imp_df_cv10_1k[, 1:2] %>% head(5), "html") %>%
  kable_styling("striped")
```

<center>**$Laufzeit \approx 2 \space Stunden \space 21 \space Minuten$**</center>

<br><br>

<center>**<u>Modell 3:</u>**</center> <br>

```{r variable_importance_cv10_2.5k, eval = FALSE}
# get variable importance of model 4
var_imp_df_cv10_2.5k <- data.frame(Variable = rownames(varImp(model_knn_cv10_2.5k)[[1]]), Importance = varImp(model_knn_cv10_2.5k)[[1]]$Overall,
                                  Rank = rank(varImp(model_knn_cv10_2.5k)[[1]]$Overall)) %>%
  arrange(desc(Rank))
```

```{r var_imp_cv10_2.5k_table}
# display variable importance of model 4
kable(var_imp_df_cv10_2.5k[, 1:2] %>% head(5), "html") %>%
  kable_styling("striped")
```

<center>**$Laufzeit \approx 5 \space Stunden \space 57 \space Minuten$**</center>

Kostenvergleich {data-orientation=rows}
=======================================================
Um die Kostenersparnis unseres "Siegermodells" festzustellen benötigen wir Vergleichswerte. Nehmen wir im Folgenden an, es existieren keine datenanalytischen Methoden um dem Luftdruckssystemfehler in gewisser Weise vorzubeugen. Wie würde man vorgehen?

Row  {data-height=300}
------------------------------------------------------

### **Guessing at Random**
Eine Möglichkeit bietet sich darin, einfach zu raten. Sicherlich nicht besonders effektiv, aber vielleicht lassen sich so ein paar der betroffenen LKW's vorsorglich in die Werkstatt schicken. <br>

<center>
```{r guessing_at_random}
random_class <- character(length = length(data_trucks_test))
rand_num <- runif(16000)
random_class <- ifelse(rand_num < 0.5, "pos", "neg")

random_conf <- confusionMatrix(random_class, data_trucks_test$class)
random_conf

random_table <- random_conf$table %>% as.data.frame() %>% extract2("Freq") 
random_cost <- random_table[2] * 10 + random_table[3] * 500
```
</center>

<br><br>

<u>**Kosten: **</u>`r random_cost` <br>
<u>**Kosten pro LKW: **</u>`r random_cost/nrow(data_trucks_test)` <br>

Im Vergleich ergibt sich folgendes Güte unseres Modells: <br>

<u>**Kosteneffizienz: **</u> Verbesserung um $\approx$ `r floor(((random_cost / min_cost_cv10_2.5k) * 100) - 100)`%

### **Das wird schon**
Eine weiter Möglichkeit wäre, auf sein Glück zu vertrauen und keinen LKW in die Werkstatt zu schicken, "das wird schon". Auch wenn das sehr riskant ist, sind, wie bereits in der Datensatzanalyse gezeigt, nur wenige der LKW's üerhaupt betroffen. <br>

<center>
```{r complete_luck}
luck_class <- rep("neg", 16000)

luck_conf <- confusionMatrix(luck_class, data_trucks_test$class)
luck_conf

luck_table <- luck_conf$table %>% as.data.frame() %>% extract2("Freq")
luck_cost <- luck_table[2] * 10 + luck_table[3] * 500
```
</center>

<br><br>

<u><i>**Kosten: **</i></u>`r luck_cost` <br> 
<u><i>**Kosten pro LKW: **</i></u>`r luck_cost/nrow(data_trucks_test)`<br> 

Im Vergleich ergibt sich folgendes Güte unseres Modells: <br>

<u>**Kosteneffizienz: **</u> Verbesserung um $\approx$ `r floor(((luck_cost / min_cost_cv10_2.5k) * 100) - 100)`%

### **Sicher ist sicher**
Eine letzte Möglichkeit liefert die "Sicherheitsvariante". Wenn man jeden LKW in die Werkstatt schickt, kann zumindest kein Fehler übersehen werden, aber auch das bringt natürlich gewisse Kosten mit sich. <br>

<center>
```{r safe}
safe_class <- rep("pos", 16000)

safe_conf <- confusionMatrix(safe_class, data_trucks_test$class)
safe_conf
safe_table <- safe_conf$table %>% as.data.frame() %>% extract2("Freq")
safe_cost <- safe_table[2] * 10 + safe_table[3] * 500
```
</center>

<br><br>

<u><i>**Kosten: **</i></u>`r safe_cost` <br> 
<u><i>**Kosten pro LKW: **</i></u>`r safe_cost/nrow(data_trucks_test)`<br> 

Im Vergleich ergibt sich folgendes Güte unseres Modells: <br>

<u>**Kosteneffizienz: **</u> Verbesserung um $\approx$ `r floor(((safe_cost / min_cost_cv10_2.5k) * 100) - 100)`%

Row {data-height=100}
-------------------------------------------------------

### **Fazit**
Natürlich gäbe es noch mehr Möglichkeiten, in dem man beispielsweise eine Stichprobe der Größe *n* in die Werkstatt schickt und den Rest so fahren lässt, es zeigt sich aber doch sehr deutlich, wie kostenintensiv solche Problematiken ohne Datenanalytik werden können. <br><br>
Vertraut Scania auf die getroffenen Vorhersagen, so entstehen durchschnittlich 0.57 Kosten pro LKW, schickt die Firma zufällig LKW's in die Werkstatt, entstehen schnell Kosten von über 10 pro LKW. <br><br>
Die Kostenminimierung ist also ein essenzieller Bestandteil moderner Unternehmen und aus dem Handwerkskasten der Statistiker und Analytiker nicht mehr wegzudenken.

Über Uns {data-orientation=rows}
=======================================================

<u>Über die eoda GmbH:</u> <br>
eoda ist ein auf Data Science spezialisiertes IT-Unternehmen. Das Portfolio umfasst Consulting, Analytic Services, Software und Training. Die Leistungen erstrecken sich dabei über den gesamten Workflow vom Datenmanagement über die Analyse und Interpretation der Ergebnisse bis hin zur Integration von Analyse-Workflows in bestehende Prozesse und Applikationen. Das interdisziplinäre Team von eoda kombiniert fundiertes Wissen über Geschäftsprozesse mit der kompetenten Anwendung der passenden statistischen Analyseverfahren.

Als Pionier in Deutschland für die Open Source Programmiersprache R bietet eoda ein umfassendes Portfolio für den produktiven Einsatz von R. Spark, AI-Frameworks wie tensorflow oder MxNet und andere Data-Science-Sprachen wie Python und Julia vervollständigen unser Toolkit und helfen uns, die täglichen Herausforderungen von Data Science zu meistern.

eoda bietet ein ganzheitliches Trainings- und Qualifizierungskonzept für R und Python. Wir bieten Schulungen in deutscher und englischer Sprache an.

Für weitere Informationen, kontaktieren Sie uns über:
<center><a href="www.eoda.de">www.eoda.de</a></center>

<br><br><br><br><br><br><br><br>

<u>About eoda GmbH:</u> <br>
eoda is an IT company specialized in data science. Its portfolio comprises consulting, analytic services, software and training. The services cover the entire workflow from data acquisition to analysis to the interpretation of results and the integration of analysis workflows into existing processes and applications. The interdisciplinary team of eoda combines a profound knowledge of business processes with a competent usage of suitable methods for statistical analysis.

As a pioneer in Germany for the open source statistical language R, eoda provides a comprehensive portfolio for the productive application of R. The use of spark, AI frameworks like tensorflow or MxNet and other data science languages like Python and Julia complete our toolkit and help us master the daily challenges of data science.

eoda provides a unique holistic training and qualification concept for R and Python. We can provide trainings in both German and English.

For further information, contact us on:
<center><a href = "www.eoda.de">www.eoda.de</a></center>

<br><br><br><br><br><br><br><br><br>

<center><img src = "eoda_logo.png" alt = "Logo" height = "35%" width = "35%"></center>





